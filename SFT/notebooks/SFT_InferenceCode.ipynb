{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2ZBKPaZTVut",
        "outputId": "5d6518de-3bd1-4a66-8bea-a89af930b09a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MScqmpEmTN80",
        "outputId": "2aeafd95-ec2d-42c6-ade4-041a26e30d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 50, but your input_length is only 11. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response:\n",
            "Adam optimization is a technique where a model is optimized to optimize the performance of an algorithm by minimizing the number of steps it takes to achieve a goal.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_id = \"/content/drive/MyDrive/RLHF/SFT/output/checkpoint-138\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "\n",
        "responser = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "max_target_length = 50\n",
        "\n",
        "input_dialogue = \"\"\"\n",
        "What is Adam optimization?\n",
        "\"\"\"\n",
        "\n",
        "input_text = \"Response: \" + input_dialogue\n",
        "\n",
        "response = responser(input_text, max_length=max_target_length, min_length=30, do_sample=False)\n",
        "\n",
        "print(\"Generated Response:\")\n",
        "print(response[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hj8WQ1HIUBNt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}